{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3a0717-f222-4675-a6e5-4c9c5f14a74d",
   "metadata": {},
   "source": [
    "# Goal: a scene classification model that classifies an image to one of 6 labels:\n",
    "- Buildings\n",
    "- Forests\n",
    "- Mountains\n",
    "- Glacier\n",
    "- Street\n",
    "- Sea\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/nitishabharathi/scene-classification?resource=download&select=train-scene+classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79f0cb-ac68-4603-8ccf-4b3f2b3e2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we'll use below.\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import metrics\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ca2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c391db47-3e23-4ace-b8a7-40320cce9a37",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4cc43b-f32c-41af-a4f9-52bb00aa8c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def generate_xy(df, resize=False):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in df.iterrows():\n",
    "        img_name = i[1]['image_name']\n",
    "        img = Image.open(f'train-scene classification/train/{img_name}')\n",
    "        img_arr = np.array(img)\n",
    "        if img_arr.shape[0] == 150:\n",
    "            X.append(np.array(img))\n",
    "            Y.append(i[1]['label'])\n",
    "        elif resize:\n",
    "            X.append(np.array(img.resize((150,150))))\n",
    "            Y.append(i[1]['label'])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['building','forest','glacier','mountain',\n",
    "            'sea','street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c03b48-f27b-400c-b0c0-56abf35a7947",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.read_csv('train-scene classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2604eb0-ebb1-4005-99ee-c8134a95cf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = samples_df['label'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff66aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [] \n",
    "for i in classes:\n",
    "    dfs.append(samples_df[samples_df.label==i].sample(n=2500))\n",
    "\n",
    "sub_samples_df = pd.concat(dfs)\n",
    "sub_samples_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = sub_samples_df.sample(frac=.2)\n",
    "test_df = sub_samples_df[~sub_samples_df.index.isin(val_df.index)].sample(frac=.2)\n",
    "train_df = sub_samples_df[~sub_samples_df.index.isin(val_df.index) & ~sub_samples_df.index.isin(test_df.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feddd00",
   "metadata": {},
   "source": [
    "##### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614ff88-5c9c-42e1-867f-84639e70b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = generate_xy(train_df)\n",
    "val_X, val_Y = generate_xy(val_df)\n",
    "test_X, test_Y = generate_xy(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = tf.random.shuffle(tf.range(tf.shape(train_X)[0], dtype=tf.int32))\n",
    "train_X = tf.gather(train_X, shuffle).numpy()\n",
    "train_Y = tf.gather(train_Y, shuffle).numpy()\n",
    "\n",
    "shuffle = tf.random.shuffle(tf.range(tf.shape(val_X)[0], dtype=tf.int32))\n",
    "val_X = tf.gather(val_X, shuffle).numpy()\n",
    "val_Y = tf.gather(val_Y, shuffle).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60296f-26ff-4182-adec-1711619c0bbd",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c5c93-db65-4872-89e3-fdaa4b1a16eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a592fa",
   "metadata": {},
   "source": [
    "### Explore image specifics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'total training samples X: {train_X.shape[0]}')\n",
    "print(f'total training samples Y: {train_Y.shape[0]}')\n",
    "print(f'total val samples X: {val_X.shape[0]}')\n",
    "print(f'total val samples Y: {val_Y.shape[0]}')\n",
    "print(f'total test samples X: {test_X.shape[0]}')\n",
    "print(f'total test samples Y: {test_Y.shape[0]}')\n",
    "print(f'image size: {train_X.shape[1:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84b649-3698-4b67-8859-2480c59ca6e3",
   "metadata": {},
   "source": [
    "### Check class balance across train/val dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066354e-e430-4125-b405-0eb3ebf9edd7",
   "metadata": {},
   "source": [
    "#### Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac02cbd-9787-4e08-9907-8369ee5484a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = samples_df.groupby(by='label').count().reset_index()\n",
    "class_counts.rename(columns={'image_name':'counts'}, inplace=True)\n",
    "sns.barplot(x='label', y='counts', data=class_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e00e8-55ed-4bf2-bc52-1fbcdffb62c0",
   "metadata": {},
   "source": [
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3796a-2264-4fb5-bc1c-0fdf955ec13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_counts = train_df.groupby(by='label').count().reset_index()\n",
    "train_class_counts.rename(columns={'image_name':'counts'}, inplace=True)\n",
    "sns.barplot(x='label', y='counts', data=train_class_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230a719-8d8c-41a9-9fc9-347e3fe0fc1c",
   "metadata": {},
   "source": [
    "#### Val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f9f3a6-d22e-4ee2-a015-8781df43fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_class_counts = val_df.groupby(by='label').count().reset_index()\n",
    "val_class_counts.rename(columns={'image_name':'counts'}, inplace=True)\n",
    "sns.barplot(x='label', y='counts', data=val_class_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed406d6b-2130-4a94-b946-ea5299fdca19",
   "metadata": {},
   "source": [
    "#### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa356a-57d0-4101-a418-0bbd0f317483",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_class_counts = test_df.groupby(by='label').count().reset_index()\n",
    "test_class_counts.rename(columns={'image_name':'counts'}, inplace=True)\n",
    "sns.barplot(x='label', y='counts', data=test_class_counts) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4880e",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72580e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_norm = []\n",
    "for image in train_X:\n",
    "    image = image.astype('float64')\n",
    "    image *= 255.0/image.max()\n",
    "    image = image.astype('uint8')\n",
    "    train_X_norm.append(image)\n",
    "\n",
    "train_X_norm = np.array(train_X_norm)\n",
    "\n",
    "val_X_norm = []\n",
    "for image in val_X:\n",
    "    image = image.astype('float64')\n",
    "    image *= 255.0/image.max()\n",
    "    image = image.astype('uint8')\n",
    "    val_X_norm.append(image)\n",
    "\n",
    "val_X_norm = np.array(val_X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3,nrows=1,figsize=(16,6))\n",
    "\n",
    "bands = train_X.transpose(3, 0, 1, 2)\n",
    "axes[0].set_title('band 0')\n",
    "sns.histplot(np.random.choice(bands[0].ravel(), size=1000), ax=axes[0])\n",
    "axes[1].set_title('band 1')\n",
    "sns.histplot(np.random.choice(bands[1].ravel(), size=1000), ax=axes[1])\n",
    "axes[2].set_title('band 2')\n",
    "sns.histplot(np.random.choice(bands[2].ravel(), size=1000), ax=axes[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3,nrows=1,figsize=(16,6))\n",
    "\n",
    "bands = train_X_norm.transpose(3, 0, 1, 2)\n",
    "axes[0].set_title('band 0')\n",
    "sns.histplot(np.random.choice(bands[0].ravel(), size=1000), ax=axes[0])\n",
    "axes[1].set_title('band 1')\n",
    "sns.histplot(np.random.choice(bands[1].ravel(), size=1000), ax=axes[1])\n",
    "axes[2].set_title('band 2')\n",
    "sns.histplot(np.random.choice(bands[2].ravel(), size=1000), ax=axes[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f588ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2,nrows=1,figsize=(16,6))\n",
    "\n",
    "axes[0].imshow(train_X[0])\n",
    "axes[1].imshow(train_X_norm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d43d0-fb93-4df9-8c66-6b0def72b377",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f27cad",
   "metadata": {},
   "source": [
    "### Train Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7b247-7646-4839-867b-936878a8b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ffn_model(n_classes,\n",
    "                input_shape,\n",
    "                hidden_layer_sizes=[],\n",
    "                activation='relu',\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.001):\n",
    "    \"\"\"Build a multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    hidden_layer_sizes: A list with the number of units in each hidden layer.\n",
    "    activation: The activation function to use for the hidden layers.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Rescaling(1./255, input_shape=input_shape))\n",
    "    for layer_size in hidden_layer_sizes:\n",
    "        \n",
    "        model.add(keras.layers.Dense(\n",
    "          units=layer_size,\n",
    "          activation=activation,\n",
    "        ))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(\n",
    "      units=n_classes,\n",
    "      activation='softmax'\n",
    "    ))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate) if optimizer == 'SGD' \\\n",
    "             else tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                optimizer=optimizer, \n",
    "                metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3b213-0b53-46a7-8a77-ea5862c12f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ffn = build_ffn_model(n_classes=len(classes),\n",
    "                    input_shape=train_X.shape,\n",
    "                    hidden_layer_sizes=[150],\n",
    "                    activation='relu',\n",
    "                    optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c31a8c-f589-4f6a-a2d1-902c6f6d4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training...')\n",
    "n_epochs = 3\n",
    "history_ffn = model_ffn.fit(\n",
    "    x=train_X,\n",
    "    y=train_Y,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=16,\n",
    "    validation_data=(val_X, val_Y),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad002f-b4ed-46f5-ba82-7badebfb4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history_ffn.history['accuracy']\n",
    "val_accuracy = history_ffn.history['val_accuracy']\n",
    "plt.plot(train_accuracy, label='train_accuracy')\n",
    "plt.plot(val_accuracy, label='validation accuracy')\n",
    "plt.xticks(range(n_epochs))\n",
    "plt.xlabel('Train epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model_eval = model_ffn.evaluate(x=test_X, y=test_Y, verbose=0,\n",
    "                             return_dict=True)\n",
    "\n",
    "test_accuracy = model_eval['accuracy']\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a755a",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fec24b-4218-4a5e-b736-ca6238ba106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_ffn.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a784d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_predictions(samples, actual, predictions):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3)\n",
    "    fig.set_size_inches(10, 12)\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            s = i+j\n",
    "            scores = predictions[s]\n",
    "            guess = np.where(scores==scores.max())\n",
    "            axes[i][j].imshow(samples[s])\n",
    "            axes[i][j].set_title('ACTUAL: '+str(labels[actual[s]])+ \n",
    "                        ' PRED: '+str(labels[guess[0][0]]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec41424",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_predictions(test_X, test_Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46410969",
   "metadata": {},
   "source": [
    "### Train 2d CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6540daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_model(n_classes, input_shape,\n",
    "                optimizer='SGD',\n",
    "                learning_rate=0.001,\n",
    "                padding='same'):\n",
    "    \"\"\"Build a multi-class 2D CNN using Keras.\n",
    "\n",
    "    Args:\n",
    "    n_classes: Number of output classes in the dataset.\n",
    "    input_shape: The shape of the input dataset.\n",
    "    optimizer: The optimizer to use (SGD, Adam).\n",
    "    learning_rate: The desired learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(0)\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "      keras.layers.Rescaling(1./255, input_shape=input_shape),\n",
    "      keras.layers.Conv2D(16, 3, padding=padding, activation='relu'),\n",
    "      keras.layers.MaxPooling2D(),\n",
    "      keras.layers.Conv2D(32, 3, padding=padding, activation='relu'),\n",
    "      keras.layers.MaxPooling2D(),\n",
    "      keras.layers.Conv2D(64, 3, padding=padding, activation='relu'),\n",
    "      keras.layers.MaxPooling2D(),\n",
    "      keras.layers.Flatten(),\n",
    "      keras.layers.Dense(128, activation='relu'),\n",
    "      keras.layers.Dropout(rate=0.5),\n",
    "      # keras.layers.Dense(n_classes),\n",
    "    ])\n",
    "    \n",
    "    model.add(keras.layers.Dense(\n",
    "      units=n_classes,\n",
    "      activation='softmax'\n",
    "    ))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate) if optimizer == 'SGD' \\\n",
    "             else tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                optimizer=optimizer, \n",
    "                metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c713001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = train_X.shape[1:]\n",
    "model_2d = build_2d_cnn_model(n_classes=len(classes),\n",
    "                      input_shape=input_shape,\n",
    "                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3dab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2d.build()\n",
    "\n",
    "print(model_2d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa69258",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training...')\n",
    "n_epochs = 5\n",
    "cnn2d_history = model_2d.fit(\n",
    "    x=train_X,\n",
    "    y=train_Y,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(val_X, val_Y),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e70ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_curves(history, n_epochs):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(n_epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "print_curves(cnn2d_history, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19403116",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adb1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = model_2d.evaluate(x=test_X, y=test_Y, verbose=0,\n",
    "                             return_dict=True)\n",
    "\n",
    "test_accuracy = model_eval['accuracy']\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_2d.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea11511",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_predictions(test_X, test_Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b8024",
   "metadata": {},
   "source": [
    "# Cross Validation on CNN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e0b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = generate_xy(sub_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf1304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "for kfold, (train, test) in enumerate(KFold(n_splits=3, shuffle=True).split(images, labels)):\n",
    "    # clear the session \n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # calling the model and compile it \n",
    "    model = build_2d_cnn_model(len(np.unique(labels[train])),images[train].shape[1:])\n",
    "\n",
    "    print(f'Iteration {kfold}')\n",
    "\n",
    "    # run the model \n",
    "    epochs = 10\n",
    "    hist = model.fit(images[train], \n",
    "              labels[train],\n",
    "              batch_size=128, \n",
    "              epochs=10, \n",
    "              validation_data=(images[test], \n",
    "              labels[test]),\n",
    "              verbose=False\n",
    "            )\n",
    "    print_curves(hist, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b40cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
